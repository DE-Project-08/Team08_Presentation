{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e421b5",
   "metadata": {},
   "source": [
    "1. lambda_function.py - To generate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        # Configuration\n",
    "        news_api_key = 'fed8d7fc5e6b4a5a9b96fb4c3938b509'\n",
    "        bucket_name = 'tesla-stock-project-bucket'\n",
    "        output_file = 'combined_data/combined_tesla_data.csv'\n",
    "\n",
    "        # Fetch Tesla Stock Data\n",
    "        tsla_data = yf.download(\"TSLA\", period=\"7d\", interval=\"1d\", auto_adjust=False)\n",
    "        stock_lines = [\"Date,Open,Close,Volume\"]\n",
    "        for index, row in tsla_data.iterrows():\n",
    "            stock_lines.append(f\"{index.strftime('%Y-%m-%d')},{row['Open']},{row['Close']},{row['Volume']}\")\n",
    "\n",
    "        # Fetch Tesla News & Sentiment\n",
    "        url = f\"https://newsapi.org/v2/everything?q=Tesla&sortBy=publishedAt&language=en&pageSize=5&apiKey={news_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        articles = response.json().get('articles', [])\n",
    "\n",
    "        news_lines = [\"Date,SentimentScore\"]\n",
    "        for article in articles:\n",
    "            published = article.get('publishedAt', '')[:10]\n",
    "            title = article.get('title', '')\n",
    "            description = article.get('description', '')\n",
    "            content = (title + ' ' + description).lower()\n",
    "\n",
    "            # Simple Sentiment Calculation: positive words vs negative words\n",
    "            positive_words = ['good', 'great', 'positive', 'growth', 'profit', 'successful', 'win']\n",
    "            negative_words = ['bad', 'poor', 'loss', 'decline', 'negative', 'fail', 'drop']\n",
    "\n",
    "            score = 0\n",
    "            for word in positive_words:\n",
    "                if word in content:\n",
    "                    score += 1\n",
    "            for word in negative_words:\n",
    "                if word in content:\n",
    "                    score -= 1\n",
    "\n",
    "            news_lines.append(f\"{published},{score}\")\n",
    "\n",
    "        # Merge Data (by Date)\n",
    "        stock_dict = {}\n",
    "        for line in stock_lines[1:]:\n",
    "            parts = line.split(',')\n",
    "            stock_dict[parts[0]] = parts[1:]\n",
    "\n",
    "        final_lines = [\"Date,Open,Close,Volume,SentimentScore\"]\n",
    "        for line in news_lines[1:]:\n",
    "            parts = line.split(',')\n",
    "            date = parts[0]\n",
    "            sentiment = parts[1]\n",
    "            if date in stock_dict:\n",
    "                final_lines.append(f\"{date},{','.join(stock_dict[date])},{sentiment}\")\n",
    "\n",
    "        # Upload to S3\n",
    "        csv_buffer = StringIO()\n",
    "        csv_buffer.write(\"\\n\".join(final_lines))\n",
    "\n",
    "        s3 = boto3.client('s3')\n",
    "        s3.put_object(Bucket=bucket_name, Key=output_file, Body=csv_buffer.getvalue())\n",
    "\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps('‚úÖ Tesla Combined Stock + News Data Saved to S3 Successfully!')\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f'‚ùå Error: {str(e)}')\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1edb9",
   "metadata": {},
   "source": [
    "2. Training the ML Model - RandomForest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8152119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import boto3\n",
    "\n",
    "# Step 1: Load cleaned dataset from S3\n",
    "s3_path = \"s3://tesla-stock-sentiment-analysis/tesla_balanced_training_data.csv\"\n",
    "df = pd.read_csv(s3_path)\n",
    "\n",
    "# Step 2: Add new key feature\n",
    "df['PriceChange'] = df['Close'] - df['Open']\n",
    "\n",
    "# Step 3: Prepare feature and label sets\n",
    "X = df[['Open', 'Close', 'Volume', 'SentimentScore', 'PriceChange']]\n",
    "y = df['Label']\n",
    "\n",
    "# step 4: Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train RandomForest model\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Step 7: Save the model locally\n",
    "local_file = \"tesla_model_fixed.pkl\"\n",
    "joblib.dump(model, local_file)\n",
    "print(f\"Model saved locally as {local_file}\")\n",
    "\n",
    "# step 8: Upload to S3\n",
    "bucket = \"tesla-stock-sentiment-analysis\"\n",
    "s3_key = \"tesla_model.pkl\"\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file(local_file, bucket, s3_key)\n",
    "print(f\"Model uploaded to s3://{bucket}/{s3_key}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42afaf",
   "metadata": {},
   "source": [
    "3. Predction using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import boto3\n",
    "\n",
    "# Step 1: Load model from S3\n",
    "bucket_name = \"tesla-stock-sentiment-analysis\"\n",
    "s3_key = \"tesla_model.pkl\"\n",
    "local_model_file = \"tesla_model_downloaded.pkl\"\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket_name, s3_key, local_model_file)\n",
    "model = joblib.load(local_model_file)\n",
    "print(\"Model loaded from S3 successfully!\")\n",
    "\n",
    "# Step 2: Ask user for TODAY's market input\n",
    "try:\n",
    "    open_price = float(input(\"Enter TODAY's OPEN price: \"))\n",
    "    close_price = float(input(\"Enter TODAY's CLOSE price: \"))\n",
    "    volume = int(input(\"Enter TODAY's VOLUME: \"))\n",
    "except ValueError:\n",
    "    print(\"‚ö†Ô∏è Please enter valid numbers.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# step 3: Auto-compute remaining features\n",
    "price_change = close_price - open_price\n",
    "sentiment_score = 0.4 if price_change > 0 else -0.3  # simple rule for now\n",
    "\n",
    "# Step 4: Prepare DataFrame for prediction\n",
    "input_data = pd.DataFrame([{\n",
    "    'Open': open_price,\n",
    "    'Close': close_price,\n",
    "    'Volume': volume,\n",
    "    'SentimentScore': sentiment_score,\n",
    "    'PriceChange': price_change\n",
    "}])\n",
    "\n",
    "# Reorder columns to match training\n",
    "input_data = input_data[['Open', 'Close', 'Volume', 'SentimentScore', 'PriceChange']]\n",
    "\n",
    "# Step 5: Predict tomorrow's trend\n",
    "prediction = model.predict(input_data)[0]\n",
    "\n",
    "# Step 6: Show prediction\n",
    "print(\"\\nüîÆ Prediction for TOMORROW:\")\n",
    "if prediction == 1:\n",
    "    print(\"üìà Tesla stock is predicted to go UP üöÄ\")\n",
    "else:\n",
    "    print(\"üìâ Tesla stock is predicted to go DOWN üìâ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fba29c",
   "metadata": {},
   "source": [
    "4. Deploying Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82788685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import joblib\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set Streamlit page config\n",
    "st.set_page_config(page_title=\"Tesla Stock Predictor\", layout=\"centered\")\n",
    "\n",
    "# Constants and secrets\n",
    "NEWS_API_KEY = st.secrets[\"api\"][\"NEWS_API_KEY\"]\n",
    "\n",
    "# S3 Details\n",
    "BUCKET_NAME = \"tesla-stock-sentiment-analysis\"\n",
    "S3_KEY = \"tesla_model_fixed.pkl\"\n",
    "\n",
    "# Load model from S3 directly into memory\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    response = s3.get_object(Bucket=BUCKET_NAME, Key=S3_KEY)\n",
    "    model_bytes = response['Body'].read()\n",
    "    model = joblib.load(io.BytesIO(model_bytes))\n",
    "    return model\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "# Fetch real-time Tesla news sentiment\n",
    "def fetch_sentiment_score():\n",
    "    url = f\"https://newsapi.org/v2/everything?q=Tesla&sortBy=publishedAt&language=en&apiKey={NEWS_API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    articles = response.json().get(\"articles\", [])\n",
    "\n",
    "    headlines = []\n",
    "    for art in articles[:5]:\n",
    "        headlines.append({\n",
    "            \"title\": art.get(\"title\", \"No Title\"),\n",
    "            \"description\": art.get(\"description\", \"No Description\"),\n",
    "            \"publishedAt\": art.get(\"publishedAt\", \"\")[:19].replace(\"T\", \" \")\n",
    "        })\n",
    "\n",
    "    classifier = pipeline(\"sentiment-analysis\")\n",
    "    texts = [f\"{a['title']}. {a['description']}\" for a in headlines]\n",
    "    sentiments = classifier(texts)\n",
    "    avg_score = sum(1 if s[\"label\"] == \"POSITIVE\" else -1 for s in sentiments) / len(sentiments)\n",
    "\n",
    "    return round(avg_score, 3), headlines\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"üìä Tesla Stock Movement Predictor\")\n",
    "st.markdown(\"Enter **TODAY'S** stock data to predict **TOMORROW'S** movement.\")\n",
    "\n",
    "open_price = st.number_input(\"Open Price (Today)\", value=0.0)\n",
    "close_price = st.number_input(\"Close Price (Today)\", value=0.0)\n",
    "volume = st.number_input(\"Volume Traded (Today)\", value=0)\n",
    "\n",
    "if st.button(\"üîç Predict Tomorrow's Movement\"):\n",
    "    price_change = close_price - open_price\n",
    "    sentiment_score, news_articles = fetch_sentiment_score()\n",
    "\n",
    "    input_data = pd.DataFrame([{\n",
    "        \"Open\": open_price,\n",
    "        \"Close\": close_price,\n",
    "        \"Volume\": volume,\n",
    "        \"SentimentScore\": sentiment_score,\n",
    "        \"PriceChange\": price_change\n",
    "    }])[\"Open Close Volume SentimentScore PriceChange\".split()]\n",
    "\n",
    "    prediction = model.predict(input_data)[0]\n",
    "    direction = \"UP\" if prediction == 1 else \"DOWN\"\n",
    "\n",
    "    if prediction == 1:\n",
    "        st.success(\"üìà Tesla stock is predicted to go UP tomorrow üöÄ\")\n",
    "    else:\n",
    "        st.error(\"üìâ Tesla stock is predicted to go DOWN tomorrow üìâ\")\n",
    "\n",
    "    # Show Tesla news\n",
    "    st.markdown(\"### üì∞ Current Tesla News Headlines\")\n",
    "    for i, a in enumerate(news_articles):\n",
    "        st.markdown(f\"**{i+1}. {a['title']}**\")\n",
    "        st.markdown(f\"üïí *{a['publishedAt']}*\")\n",
    "        st.markdown(f\"üìù {a['description'] or 'No Description Available'}\")\n",
    "        st.markdown(\"---\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
